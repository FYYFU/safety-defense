from typing import List, Union

import torch
from datasets import Dataset
from tqdm import tqdm
from transformers import (
    AutoModelForSequenceClassification,
    AutoTokenizer,
    DataCollatorWithPadding,
)

REDTEAM_MODEL = "safepaca/absolute-harmfulness-predictor-redteam"
READTEAM_OSST_MODEL = "safepaca/absolute-harmfulness-predictor-redteam-osst"


class ConversationBuilder:
    def build(
        self, user_texts: Union[str, List[str]], assistant_texts: Union[str, List[str]]
    ):
        """Build a conversation from a list of user and assistant texts.

        Note: the number of turns in the conversation is determined by the length of the user_texts list.
        """
        if not isinstance(user_texts, list):
            user_texts = [user_texts]
        if not isinstance(assistant_texts, list):
            assistant_texts = [assistant_texts]

        turns = len(user_texts)
        conv = ""
        for turn_id in range(turns):
            conv += f"\n\nHuman: {user_texts[turn_id]}\n\nAssistant: {assistant_texts[turn_id]}"
        return conv


class AbsoluteHarmfulnessPredictor:
    def __init__(self, setup_name="redteam-osst", device=None):
        """Initialize the absolute harmfulness predictor.

        Args:
            setup_name (str): Name of the setup to use. Can be one of 'redteam' or 'redteam-osst'. Redteam uses a regression model fine-tuned on the RedTeam dataset. Redteam-osst uses a similar model but finetuned on the mix of RedTeam and OSST data. See our paper for more details.
        """

        device = (
            device
            if device is not None
            else "cuda:0"
            if torch.cuda.is_available()
            else "cpu"
        )

        model_id = REDTEAM_MODEL if setup_name == "redteam" else READTEAM_OSST_MODEL
        self.model = AutoModelForSequenceClassification.from_pretrained(model_id).to(
            device
        )
        self.model.eval()
        self.tokenizer = AutoTokenizer.from_pretrained(model_id)

    @torch.no_grad()
    def predict(self, user_texts: Union[str, List[str]], assistant_texts: Union[str, List[str]], batch_size=128, max_length=512, show_progress=True):
        """Predict the absolute harmfulness of a list of texts.

        Args:
            user_texts (Union[str, List[str]]): List of user texts.
            assistant_texts (Union[str, List[str]]): List of assistant texts.
            batch_size (int): Batch size to use for prediction. Defaults to 128.
            max_length (int): Maximum length of the input texts. Defaults to 512.
            show_progress (bool): Whether to show a progress bar.
        Returns:
            list: List of absolute harmfulness predictions.
        """

        assert len(user_texts) == len(assistant_texts)

        # Build the conversation with the correct template.
        conversation = ConversationBuilder()
        texts = [conversation.build(u, a) for u, a in zip(user_texts, assistant_texts)]

        raw_dataset = Dataset.from_dict({"text": texts})

        proc_dataset = raw_dataset.map(
            lambda x: self.tokenizer(
                x["text"], padding=False, truncation=True, max_length=max_length
            )
        )
        proc_dataset.set_format("torch", columns=["input_ids", "attention_mask"])
        collator = DataCollatorWithPadding(self.tokenizer, pad_to_multiple_of=8)
        train_loader = torch.utils.data.DataLoader(
            proc_dataset, shuffle=False, batch_size=batch_size, collate_fn=collator
        )

        preds = list()
        for batch in tqdm(
            train_loader, total=len(train_loader), disable=not show_progress
        ):
            batch = {k: v.to(self.model.device) for k, v in batch.items()}
            outputs = self.model(**batch)
            ps = outputs.logits[:, 0].tolist()
            preds.extend(ps)

        return preds